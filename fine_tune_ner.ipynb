{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCz/nOEXYURBWKeGAi3h3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/metasebiya/ethiomart-llm-challenge-week4/blob/task-3/fine_tune_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KQdO-qTQ8y9t",
        "outputId": "528810d4-ab97-49d5-835e-bd61cc36013e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed and imported successfully!\n",
            "Parsing CoNLL file from: labeled_dataset.txt\n",
            "Warning: Skipping malformed line in CoNLL: 'የሆነው    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'ይጠቀሙ'\n",
            "Warning: Skipping malformed line in CoNLL: 'nn'\n",
            "Warning: Skipping malformed line in CoNLL: 'carrier I-PRODUCT'\n",
            "Warning: Skipping malformed line in CoNLL: 'nn  O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'humidifiern I-PRODUCT'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'humidifier I-PRODUCT'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'socks   I-PRODUCT'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'socks   I-PRODUCT'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'padsn'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'አድራሻ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Warning: Skipping malformed line in CoNLL: 'nnመገናኛ  B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'መሰረት    B-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ደፋር I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሞል  I-LOC'\n",
            "Warning: Skipping malformed line in CoNLL: 'ሁለተኛ    O'\n",
            "Loaded 1053 sentences/messages.\n",
            "\n",
            "First sample:\n",
            "{'tokens': ['የኛ', 'እጣ', 'ባለ', 'እድለኛ', 'nndlc', 'espresso', 'coffee', 'maker', 'ባለእድለኛ', 'የሆነችውን', 'ከተወሰነ', 'በኋላ', 'እናሳውቃለን'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'B-PRODUCT', 'I-PRODUCT', 'O', 'O', 'O', 'O', 'O']}\n",
            "\n",
            "Second sample:\n",
            "{'tokens': ['ኛnnእጣ', 'ባለ', 'እድለኛ'], 'ner_tags': ['O', 'O', 'O']}\n",
            "\n",
            "Unique NER labels found: ['B-LOC', 'B-PRODUCT', 'I-LOC', 'I-PRODUCT', 'O']\n",
            "Label to ID mapping: {'B-LOC': 0, 'B-PRODUCT': 1, 'I-LOC': 2, 'I-PRODUCT': 3, 'O': 4}\n",
            "\n",
            "Training dataset size: 842\n",
            "Evaluation dataset size: 211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Davlan/afro-xlmr-large-amharic is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/Davlan/afro-xlmr-large-amharic/resolve/main/tokenizer_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    471\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1534\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1451\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m429\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    458\u001b[0m             )\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-685be813-5c32f8b06d0f92cb423b8458;b75bd38b-e929-4372-aceb-fc5f40d5ecf4)\n\nRepository Not Found for url: https://huggingface.co/Davlan/afro-xlmr-large-amharic/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1375218378.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# model_checkpoint = \"xlm-roberta-base\" # If you choose xlm-roberta-base, make sure to add the correct `num_labels` for your task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m model = AutoModelForTokenClassification.from_pretrained(\n\u001b[1;32m    125\u001b[0m     \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We cannot recover from them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGatedRepoError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Davlan/afro-xlmr-large-amharic is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "# --- Step 1: Environment Setup and Library Installation ---\n",
        "# Run this cell first in Google Colab\n",
        "\n",
        "!pip install transformers datasets seqeval evaluate accelerate -U -qq\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Features, Value, ClassLabel, Sequence\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "print(\"Libraries installed and imported successfully!\")\n",
        "\n",
        "# --- Step 2: Prepare and Load the Labeled Dataset (CoNLL Format) ---\n",
        "# IMPORTANT: You need to upload your 'labeled_dataset.txt' to your Colab environment\n",
        "# You can do this by clicking the folder icon on the left sidebar in Colab, then\n",
        "# clicking the 'Upload to session storage' icon and selecting your file.\n",
        "\n",
        "# A. Define a function to parse CoNLL format\n",
        "def parse_conll_file(file_path):\n",
        "    \"\"\"\n",
        "    Parses a CoNLL-formatted text file into a list of dictionaries,\n",
        "    where each dictionary represents a sentence with 'tokens' and 'ner_tags'.\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    current_tokens = []\n",
        "    current_labels = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line: # If line is not empty\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) == 2:\n",
        "                    token, label = parts\n",
        "                    current_tokens.append(token)\n",
        "                    current_labels.append(label)\n",
        "                else:\n",
        "                    # Handle lines that might not be correctly formatted (e.g., just a token)\n",
        "                    # For robust parsing, ensure your CoNLL is consistently token<TAB>label\n",
        "                    print(f\"Warning: Skipping malformed line in CoNLL: '{line}'\")\n",
        "            else: # Empty line signifies end of a sentence/message\n",
        "                if current_tokens: # If there are tokens accumulated\n",
        "                    sentences.append({\"tokens\": current_tokens, \"ner_tags\": current_labels})\n",
        "                    current_tokens = []\n",
        "                    current_labels = []\n",
        "        # Add the last sentence if the file doesn't end with a blank line\n",
        "        if current_tokens:\n",
        "            sentences.append({\"tokens\": current_tokens, \"ner_tags\": current_labels})\n",
        "    return sentences\n",
        "\n",
        "# Upload your labeled_dataset.txt to Colab session storage\n",
        "conll_file_path = 'labeled_dataset.txt'\n",
        "\n",
        "# Parse the CoNLL file\n",
        "print(f\"Parsing CoNLL file from: {conll_file_path}\")\n",
        "raw_data = parse_conll_file(conll_file_path)\n",
        "\n",
        "# Verify a few samples\n",
        "print(f\"Loaded {len(raw_data)} sentences/messages.\")\n",
        "if raw_data:\n",
        "    print(\"\\nFirst sample:\")\n",
        "    print(raw_data[0])\n",
        "    print(\"\\nSecond sample:\")\n",
        "    if len(raw_data) > 1:\n",
        "        print(raw_data[1])\n",
        "    else:\n",
        "        print(\"Only one sample available.\")\n",
        "else:\n",
        "    print(\"No data parsed. Check your CoNLL file format.\")\n",
        "\n",
        "# Create a dummy dataset structure for Hugging Face `datasets` library\n",
        "# First, collect all unique labels to define the ClassLabel feature\n",
        "all_labels = sorted(list(set(label for sentence in raw_data for label in sentence['ner_tags'])))\n",
        "# Ensure 'O' is always present and specific order if preferred, but sorted handles it.\n",
        "print(f\"\\nUnique NER labels found: {all_labels}\")\n",
        "\n",
        "# Map labels to IDs\n",
        "label_to_id = {label: i for i, label in enumerate(all_labels)}\n",
        "id_to_label = {i: label for i, label in enumerate(all_labels)}\n",
        "num_labels = len(all_labels)\n",
        "\n",
        "print(f\"Label to ID mapping: {label_to_id}\")\n",
        "\n",
        "# Convert string labels to numerical IDs\n",
        "for sentence in raw_data:\n",
        "    sentence['ner_tags'] = [label_to_id[label] for label in sentence['ner_tags']]\n",
        "\n",
        "# Define the features for the dataset\n",
        "features = Features({\n",
        "    \"tokens\": Sequence(Value(dtype='string')),\n",
        "    \"ner_tags\": Sequence(ClassLabel(names=all_labels))\n",
        "})\n",
        "\n",
        "# Load raw_data into a Hugging Face Dataset\n",
        "from datasets import Dataset\n",
        "dataset = Dataset.from_list(raw_data, features=features)\n",
        "\n",
        "# Split the dataset into training and testing (and validation if desired)\n",
        "# For simplicity, we'll use a train-test split. For larger datasets, train-val-test is better.\n",
        "train_test_split = dataset.train_test_split(test_size=0.2, seed=42) # 20% for testing\n",
        "\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "print(f\"\\nTraining dataset size: {len(train_dataset)}\")\n",
        "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
        "\n",
        "# --- Step 3: Load Pre-trained Model and Tokenizer ---\n",
        "\n",
        "# Choose your pre-trained model:\n",
        "# Option 1: \"Davlan/bert-tiny-amharic\" (smaller, faster)\n",
        "# Option 2: \"Davlan/afro-xlmr-large-amharic\" (larger XLM-R, potentially better performance)\n",
        "# Option 3: \"xlm-roberta-base\" (multilingual, general purpose, might need more fine-tuning)\n",
        "\n",
        "# model_checkpoint = \"Davlan/afro-xlmr-large-amharic\" # Recommended for Amharic performance\n",
        "# model_checkpoint = \"Davlan/bert-tiny-amharic\"\n",
        "model_checkpoint = \"xlm-roberta-base\" # If you choose xlm-roberta-base, make sure to add the correct `num_labels` for your task\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id_to_label,\n",
        "    label2id=label_to_id\n",
        ")\n",
        "\n",
        "print(f\"\\nLoaded tokenizer and model from: {model_checkpoint}\")\n",
        "print(f\"Model has {model.config.num_labels} labels configured.\")\n",
        "\n",
        "# --- Step 4: Tokenize Data and Align Labels ---\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        padding=\"max_length\" # Pad to max_length of model or tokenizer default\n",
        "    )\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word_idx that is None. We set the label to -100 so they are ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to -100 to ignore them.\n",
        "            else:\n",
        "                label_ids.append(-100) # Or optionally, set to the I-tag for consistent subword labeling\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Apply the tokenization and alignment function to the datasets\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "print(\"\\nData tokenization and label alignment complete!\")\n",
        "print(\"Example of tokenized and aligned labels (first sample):\")\n",
        "# Example of tokenized input and aligned labels\n",
        "# Note: -100 indicates tokens that should be ignored in loss calculation\n",
        "if tokenized_train_dataset:\n",
        "    first_sample_input_ids = tokenized_train_dataset[0][\"input_ids\"]\n",
        "    first_sample_tokens = tokenizer.convert_ids_to_tokens(first_sample_input_ids)\n",
        "    first_sample_labels = tokenized_train_dataset[0][\"labels\"]\n",
        "    print(list(zip(first_sample_tokens, first_sample_labels)))\n",
        "\n",
        "# --- Step 5: Set Up Training Arguments ---\n",
        "\n",
        "# Define evaluation metrics\n",
        "metric = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_labels = [[id_to_label[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [id_to_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    # Flatten the results for easier interpretation\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",               # Directory to save checkpoints and logs\n",
        "    evaluation_strategy=\"epoch\",          # Evaluate at the end of each epoch\n",
        "    learning_rate=2e-5,                   # Learning rate\n",
        "    per_device_train_batch_size=16,       # Batch size for training\n",
        "    per_device_eval_batch_size=16,        # Batch size for evaluation\n",
        "    num_train_epochs=3,                   # Number of training epochs\n",
        "    weight_decay=0.01,                    # Weight decay for regularization\n",
        "    logging_dir=\"./logs\",                 # Directory for storing logs\n",
        "    logging_steps=500,                    # Log every 500 steps\n",
        "    save_strategy=\"epoch\",                # Save the model at the end of each epoch\n",
        "    load_best_model_at_end=True,          # Load the best model after training\n",
        "    metric_for_best_model=\"f1\",           # Metric to monitor for best model selection\n",
        "    greater_is_better=True,               # Higher F1 is better\n",
        "    push_to_hub=False,                    # Set to True if you want to push to Hugging Face Hub\n",
        "    report_to=\"none\"                      # Disable wandb, mlflow etc. reporting if not needed\n",
        ")\n",
        "\n",
        "print(\"\\nTraining arguments configured.\")\n",
        "\n",
        "# --- Step 6: Fine-tune the Model with Trainer API ---\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nTraining complete!\")\n",
        "\n",
        "# --- Step 7: Evaluate the Fine-tuned Model ---\n",
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(metrics)\n",
        "\n",
        "# --- Step 8: Save the Fine-tuned Model ---\n",
        "\n",
        "# Define a directory to save your model\n",
        "model_save_path = \"./fine_tuned_ner_model\"\n",
        "trainer.save_model(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path) # Save tokenizer with the model\n",
        "\n",
        "print(f\"\\nModel saved to: {model_save_path}\")\n",
        "print(\"You can download this folder from Colab's file browser (left sidebar) to your local machine.\")\n",
        "print(\"The folder will contain 'pytorch_model.bin', 'config.json', and 'tokenizer.json' (or similar).\")"
      ]
    }
  ]
}